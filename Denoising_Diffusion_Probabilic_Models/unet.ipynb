{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestep_embedding(timesteps, embedding_dim:int):\n",
    "    '''\n",
    "    Build sinusoidal embeddings\n",
    "    positional embedding\n",
    "    몇번쨰 timestep에 대한 timestep embedding이 얼마냐?\n",
    "    '''\n",
    "    assert len(timesteps.shape) == 1\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32)*-emb)\n",
    "    emb = timesteps.type(torch.float32)[:,None] * emb[None, :]\n",
    "    emb = torch.concat([torch.sin(emb),torch.cos(emb)],axis=1)\n",
    "\n",
    "    return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSampling(nn.Module):\n",
    "    #C(channel) 수는 그대로 하되, 이미지 크기를 줄여나감\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(C, C, kernel_size=3, stride=2, padding=1)\n",
    "        # ((input + 2*padding - kernel_size )/stride) + 1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, H, W  = x.shape\n",
    "        x = self.conv(x)\n",
    "        assert x.shape == (B, C, H//2, W//2 )\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpSampling(nn.Module):\n",
    "    #C(channel) 수는 그대로 하되, 이미지 크기를 키움\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(C, C, kernel_size=3, stride=1, padding = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,C,H,W = x.shape\n",
    "        x = nn.functional.interpolate(x, size = None, scale_factor=2, mode='nearest')\n",
    "        x = self.conv(x)\n",
    "        assert x.shape == (B, C, H*2, W*2 )\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nin(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        scale = 1e-10\n",
    "        n = (in_dim + out_dim) / 2\n",
    "        limit = np.sqrt(3*scale/n)\n",
    "        self.W = nn.Parameter(torch.zeros((in_dim, out_dim), dtype=torch.float32).uniform_(-limit, limit ))\n",
    "        self.b = nn.Parameter(torch.zeros((1,out_dim,1,1), dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.einsum('bchw, co ->bowh' , x , self.W) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch, dropout_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride=1, padding =1)\n",
    "        self.dense = nn.Linear(512, out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, stride=1, padding =1)\n",
    "\n",
    "        if not (in_ch == out_ch):\n",
    "            self.nin = Nin(in_ch, out_ch)\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.nonlinearity = nn.SiLU()\n",
    "\n",
    "    def forward(self, x, temb): #temb: Batch, dim\n",
    "        '''\n",
    "        param x: (B, C, H, W)\n",
    "        param temb: (B, dim)\n",
    "        '''\n",
    "        h = self.nonlinearity(nn.functional.group_norm(x,num_groups=32))\n",
    "        h = self.conv1(h)\n",
    "\n",
    "        #add timestep embedding\n",
    "        h += self.dense(self.nonlinearity(temb))[:, :, None, None]\n",
    "\n",
    "        h = self.nonlinearity(nn.functional.group_norm(h,num_groups=32))\n",
    "        h = nn.functional.dropout(h, p=self.dropout_rate)\n",
    "        h = self.conv2(h)\n",
    "\n",
    "        if not (x.shape[1]==h.shape[1]):\n",
    "            x = self.nin(x)\n",
    "\n",
    "        return x + h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, ch):\n",
    "        super().__init__()\n",
    "        self.Q = Nin(ch, ch)\n",
    "        self.K = Nin(ch, ch)\n",
    "        self.V = Nin(ch, ch)\n",
    "        self.ch = ch\n",
    "        self.nin = Nin(ch, ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C ,H, W = x.shape\n",
    "\n",
    "        assert C == self.ch\n",
    "\n",
    "        h = nn.functional.group_norm(x, num_groups=32)\n",
    "        q=self.Q(h)\n",
    "        k=self.K(h)\n",
    "        v=self.V(h)\n",
    "\n",
    "        w = torch.einsum('bcwh, bcWH -> bwWhH', q , k) * (int(C)**(-0.5))\n",
    "        w = torch.reshape(w, [B,H,W,H*W])\n",
    "        w = torch.nn.softmax(w, dim =-1)\n",
    "        w = torch.reshape(w, [B,H,W,H,W])\n",
    "\n",
    "        h = torch.einsum('bcwh, bcWH -> bwWhH', w , v)\n",
    "        h= self.nin(h)\n",
    "\n",
    "        assert x.shape == h.shape\n",
    "        return x + h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, ch=128, in_ch=1): #black white\n",
    "        super().__init__()\n",
    "        self.ch = ch\n",
    "        self.linear1 = nn.Linear(ch, ch*4)\n",
    "        self.linear2 = nn.Linear(ch*4, ch*4)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_ch, ch, 3, stride=1, padding=1)\n",
    "\n",
    "        self.down = nn.ModuleList([\n",
    "            ResNetBlock(ch, ch),\n",
    "            ResNetBlock(ch, ch),\n",
    "            DownSampling(ch),\n",
    "            ResNetBlock(1 * ch, 2 * ch),\n",
    "            AttentionBlock(2 * ch),\n",
    "            ResNetBlock(2 * ch, 2 * ch),\n",
    "            AttentionBlock(2 * ch),\n",
    "            DownSampling(2 * ch),\n",
    "            ResNetBlock(2 * ch, 2 * ch),\n",
    "            ResNetBlock(2 * ch, 2 * ch),\n",
    "            DownSampling(2 * ch),\n",
    "            ResNetBlock(2 * ch, 2 * ch),\n",
    "            ResNetBlock(2 * ch, 2 * ch),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        '''\n",
    "        param x (torch.Tensor): batch of images (B,C,H,W)\n",
    "        param t (torch.Tensor): tensor of time steps (torch.long) [B]\n",
    "        '''\n",
    "\n",
    "        #timestep embedding\n",
    "        temb = get_timestep_embedding(t, self.ch)\n",
    "        temb = torch.nn.functional.silu(self.linear1(temb))\n",
    "        temb = self.linear2(temb)\n",
    "        assert temb.shape == (t.shape[0], self.ch*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (torch.rand(10)*10).long()\n",
    "temb = get_timestep_embedding(t, 512)\n",
    "\n",
    "downsample = DownSampling(64)\n",
    "img = torch.randn(10,64,64,64)\n",
    "h = downsample(img)\n",
    "\n",
    "upsample = UpSampling(64)\n",
    "img = upsample(h)\n",
    "\n",
    "nin = Nin(64, 64)\n",
    "img = nin(img)\n",
    "\n",
    "resnet = ResNetBlock(64, 64, 0.1)\n",
    "img = resnet(img, temb)\n",
    "\n",
    "resnet = ResNetBlock(64, 32, 0.1)\n",
    "img = resnet(img, temb)\n",
    "\n",
    "att = AttentionBlock(32)\n",
    "img = att(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
